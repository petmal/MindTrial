# Copyright (C) 2025 Petr Malik
#
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at <https://mozilla.org/MPL/2.0/>.

config:
  log-file: ""
  output-dir: "./results/{{.Year}}-{{.Month}}-{{.Day}}/"
  output-basename: "{{.Hour}}-{{.Minute}}-{{.Second}}"
  task-source: "./tasks.yaml"
  providers:
    - name: openai
      retry-policy:
        max-retry-attempts: 5
        initial-delay-seconds: 30
      client-config:
        api-key: ""
      runs:
        - name: "4o-mini - latest"
          model: "gpt-4o-mini"
          max-requests-per-minute: 3
        - name: "o1-mini - latest"
          model: "o1-mini"
          max-requests-per-minute: 20
          model-parameters:
            text-response-format: true
        - name: "o3-mini - latest (high reasoning)"
          model: "o3-mini"
          max-requests-per-minute: 20
          model-parameters:
            reasoning-effort: "high"
        - name: "o4-mini - latest (high reasoning)"
          model: "o4-mini"
          max-requests-per-minute: 20
          model-parameters:
            reasoning-effort: "high"
        - name: "o3 - latest (high reasoning)"
          model: "o3"
          max-requests-per-minute: 20
          model-parameters:
            reasoning-effort: "high"
        - name: "GPT-5 mini - latest (high reasoning)"
          model: "gpt-5-mini"
          max-requests-per-minute: 20
          model-parameters:
            reasoning-effort: "high"
        - name: "GPT-5 - latest (high reasoning)"
          model: "gpt-5"
          max-requests-per-minute: 20
          model-parameters:
            reasoning-effort: "high"
        - name: "GPT-5.2 - latest (xhigh reasoning)"
          model: "gpt-5.2"
          max-requests-per-minute: 20
          model-parameters:
            reasoning-effort: "xhigh"
            verbosity: "medium"
    - name: openrouter
      retry-policy:
        max-retry-attempts: 5
        initial-delay-seconds: 30
      client-config:
        api-key: ""
      runs:
        - name: "OpenAI GPT-5.2 (xhigh reasoning)"
          model: "openai/gpt-5.2"
          max-requests-per-minute: 20
          model-parameters:
            verbosity: "medium"
            # Pass-through parameters use OpenAI API naming (underscores).
            reasoning_effort: "xhigh"
        - name: "Google Gemma 3 27B IT (free)"
          model: "google/gemma-3-27b-it:free"
          max-requests-per-minute: 3
          model-parameters:
            response-format: "text"
    - name: google
      client-config:
        api-key: ""
      runs:
        - name: "Gemini 1.5 Flash - latest"
          model: "gemini-1.5-flash"
          max-requests-per-minute: 15
          model-parameters:
            text-response-format-with-tools: true
        - name: "Gemini 2.0 Flash - latest"
          model: "gemini-2.0-flash"
          max-requests-per-minute: 15
          model-parameters:
            text-response-format-with-tools: true
        - name: "Gemini 2.0 Flash - latest (thinking)"
          model: "gemini-2.0-flash-thinking-exp"
          max-requests-per-minute: 10
          model-parameters:
            text-response-format: true
        - name: "Gemini 2.5 Flash - latest"
          model: "gemini-2.5-flash"
          max-requests-per-minute: 3
          model-parameters:
            text-response-format-with-tools: true
        - name: "Gemini 2.5 Pro - latest"
          model: "gemini-2.5-pro"
          max-requests-per-minute: 3
          model-parameters:
            text-response-format-with-tools: true
        - name: "Gemini 3 Pro - latest (high thinking)"
          model: "gemini-3-pro-preview"
          max-requests-per-minute: 3
          model-parameters:
            thinking-level: "high"
            media-resolution: "high"
    - name: anthropic
      client-config:
        api-key: ""
      runs:
        - name: "Claude 3.7 Sonnet - latest"
          model: "claude-3-7-sonnet-latest"
          max-requests-per-minute: 10
          model-parameters:
            max-tokens: 4096
        - name: "Claude 3.7 Sonnet - latest (extended thinking)"
          model: "claude-3-7-sonnet-latest"
          max-requests-per-minute: 10
          model-parameters:
            max-tokens: 8192
            thinking-budget-tokens: 2048
        - name: "Claude 4.0 Sonnet - latest (extended thinking)"
          model: "claude-sonnet-4-0"
          max-requests-per-minute: 10
          model-parameters:
            max-tokens: 8192
            thinking-budget-tokens: 2048
        - name: "Claude 4.0 Opus - latest (extended thinking)"
          model: "claude-opus-4-0"
          max-requests-per-minute: 10
          model-parameters:
            max-tokens: 8192
            thinking-budget-tokens: 2048
        - name: "Claude 4.1 Opus - latest (extended thinking)"
          model: "claude-opus-4-1"
          max-requests-per-minute: 10
          model-parameters:
            max-tokens: 8192
            thinking-budget-tokens: 2048
        - name: "Claude 4.5 Sonnet - latest (extended thinking)"
          model: "claude-sonnet-4-5"
          max-requests-per-minute: 10
          model-parameters:
            max-tokens: 8192
            thinking-budget-tokens: 2048
    - name: deepseek
      client-config:
        api-key: ""
        request-timeout: 15m
      runs:
        - name: "DeepSeek-V3.2 - latest (thinking mode)"
          model: "deepseek-reasoner"
          max-requests-per-minute: 15
        - name: "DeepSeek-V3.2 - latest (non-thinking mode)"
          model: "deepseek-chat"
          max-requests-per-minute: 15
    - name: mistralai
      retry-policy:
        max-retry-attempts: 5
        initial-delay-seconds: 30
      client-config:
        api-key: ""
      runs:
        - name: "Mistral Large - latest"
          model: "mistral-large-latest"
          max-requests-per-minute: 5
        - name: "Magistral Medium - latest (reasoning)"
          model: "magistral-medium-latest"
          max-requests-per-minute: 5
          model-parameters:
            prompt-mode: "reasoning"
        - name: "Pixtral Large - latest (vision)"
          model: "pixtral-large-latest"
          max-requests-per-minute: 5
          model-parameters:
            prompt-mode: "reasoning"
    - name: xai
      retry-policy:
        max-retry-attempts: 5
        initial-delay-seconds: 30
      client-config:
        api-key: ""
      runs:
        - name: "Grok 4 - latest (reasoning)"
          model: "grok-4-latest"
          max-requests-per-minute: 30
    - name: alibaba
      retry-policy:
        max-retry-attempts: 5
        initial-delay-seconds: 30
      client-config:
        api-key: ""
        endpoint: "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
      runs:
        - name: "Qwen3-Max-Preview"
          model: "qwen3-max-preview"
          max-requests-per-minute: 30
        - name: "Qwen-VL-Max-Latest"
          model: "qwen-vl-max-latest"
          max-requests-per-minute: 30
          model-parameters:
            disable-legacy-json-mode: true
        - name: "Qwen3-235B-A22B-Thinking-2507"
          model: "qwen3-235b-a22b-thinking-2507"
          max-requests-per-minute: 30
          model-parameters:
            text-response-format: true
        - name: "Qwen3-Next-80B-A3B-Thinking"
          model: "qwen3-next-80b-a3b-thinking"
          max-requests-per-minute: 30
          model-parameters:
            text-response-format: true
    - name: moonshotai
      retry-policy:
        max-retry-attempts: 5
        initial-delay-seconds: 30
      client-config:
        api-key: ""
      runs:
        - name: "Kimi - latest (vision)"
          model: "kimi-latest"
          max-requests-per-minute: 3
          model-parameters:
            temperature: 0.6
        - name: "Kimi K2 - latest (thinking)"
          model: "kimi-k2-thinking"
          max-requests-per-minute: 3
          model-parameters:
            temperature: 1.0
  judges:
    - name: "default"
      provider:
        name: "mistralai"
        client-config:
          api-key: ""
        runs:
          - name: "fast"
            model: "mistral-medium-latest"
            max-requests-per-minute: 30
            model-parameters:
              temperature: 0.20
              random-seed: 847629
          - name: "reasoning"
            model: "magistral-medium-latest"
            max-requests-per-minute: 30
            model-parameters:
              prompt-mode: "reasoning"
              temperature: 0.20
              random-seed: 847629
  tools:
    - name: python-code-executor
      image: python:latest
      description: |
        Executes Python 3 code in a secure, sandboxed environment to perform calculations, data manipulation, or algorithmic tasks.
        IMPORTANT:
        - Only the Python standard library is available. No third-party packages (like pandas or numpy) can be imported.
        - The environment has no network access.
        - Any files mentioned in the conversation (shown as [file: filename]) are automatically mounted to /app/data/ with their exact filenames.
        - Use standard file operations like open('/app/data/filename', 'r') to read attached files, where 'filename' matches the name shown in [file: filename] references.
        - A persistent shared directory is available at /app/shared/ that persists across ALL tool calls within the same task (regardless of which tool is being called). Files created in this directory will be available in any subsequent tool call.
        - Any files or changes outside of /app/shared/ are ephemeral and will be reset between tool calls.
        - The code must print its final result to standard output to be returned.
      parameters:
        type: object
        properties:
          code:
            type: string
            description: "A string containing a self-contained Python 3 script. The script must use the `print()` function to return a final result. Example: `print(sum([i for i in range(101) if i % 2 == 0]))`. To read attached files, use open('/app/data/filename', 'r') where 'filename' matches what appears in [file: filename] references."
        required:
          - code
        additionalProperties: false
      parameter-files:
        code: /app/main.py
      auxiliary-dir: /app/data
      shared-dir: /app/shared
      command:
        - python
        - /app/main.py
      env:
        PYTHONIOENCODING: "UTF-8"
        PYTHONUNBUFFERED: "1"
        PYTHONHASHSEED: "847629"
